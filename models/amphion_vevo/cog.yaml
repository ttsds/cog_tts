# Configuration for Cog ⚙️
# Reference: https://cog.run/yaml

build:
  # Set to true if your model requires a GPU
  gpu: true

  system_packages:
    - git
    - espeak-ng
    - gcc
    - build-essential
    - g++-12
    - git-lfs
    - cmake
    - ffmpeg
    

  python_version: "3.10"

  # Python packages to install in your environment
  python_packages:
    - "setuptools==67.8.0"
    - "scipy==1.12.0"
    - "numpy>=1.21.5"

    # PyTorch ecosystem
    - "torch==2.0.1"
    - "torchaudio==2.0.2"
    - "torchvision==0.15.2"
    - "onnxruntime==1.15.1"

    # Hugging Face and related
    - "transformers==4.41.2"
    - "accelerate==0.24.1"

    # Text / NLP
    - "unidecode==1.3.6"
    - "phonemizer==3.2.1"
    - "g2p_en==2.1.0"
    - "jieba==0.42.1"
    - "cn2an==0.5.0"
    - "pypinyin==0.48.0"
    - "LangSegment==0.3.5"
    - "pykakasi==2.2.1"
    - "pyworld==0.3.5"

    # Audio / Speech
    - "librosa==0.10.0"
    - "encodec==0.1.1"
    - "openai-whisper==20240930"

    # Utilities
    - "json5==0.9.11"
    - "ruamel.yaml<0.18.0"
    - "tqdm==4.65.0"

    # Misc
    - "black==24.1.1"
    - "ipython==8.31.0"

  # Commands run after the environment is set up
  run:
    # Install pyopenjtalk
    - "pip install pyopenjtalk==0.3.0 --no-build-isolation"
    # Clone Amphion
    - "echo 'Cloning Amphion...'"
    - "git clone https://github.com/open-mmlab/Amphion.git"
    - "cd Amphion && git checkout 04dfe6e"

# predict.py defines how predictions are run on your model
predict: "predict.py:Predictor"

image: "r8.im/ttsds/amphion_vevo"
