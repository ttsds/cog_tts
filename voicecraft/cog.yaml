# Configuration for Cog ⚙️
# Reference: https://cog.run/yaml

build:
  # set to true if your model requires a GPU
  gpu: true

  # git git-lfs libsox-dev ffmpeg gcc build-essential g++-12 espeak-ng
  system_packages:
    - git
    - git-lfs
    - libsox-dev
    - ffmpeg
    - gcc
    - build-essential
    - g++-12
    - espeak-ng

  # python version in the form '3.11' or '3.11.4'
  python_version: "3.10"

  # a list of packages in the format <package-name>==<version>
  python_packages:
    - torchaudio==2.1.0
    - torch==2.1.0
    - xformers==0.0.22.post4
    - git+https://github.com/dillionverma/audiocraft@677b88630b312af7ba8a0d1a886bee08a97e85aa
    - hydra-core
    - omegaconf
    - tensorboard==2.16.2
    - phonemizer==3.2.1
    - datasets==2.16.0
    - torchmetrics==0.11.1
    - numpy<2
    - huggingface_hub
    - whisperx
    - num2words==0.5.13
    - nltk>=3.8.1

  run:
    - pip install --upgrade faster-whisper
    # voicecraft
    - git clone https://github.com/jasonppy/VoiceCraft.git voicecraft
    - cd voicecraft && git checkout 4873249

# predict.py defines how predictions are run on your model
predict: "predict.py:Predictor"

image: "r8.im/ttsds/voicecraft"